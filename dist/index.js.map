{"version":3,"file":"index.js","mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAcA;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;;;;;;;;;;;;;;;;;;AAkBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;;;;;;;;AAAA;;;;;;;;AAAA;;;;;;;;AAAA;;;;;;;;AAAA;;;;;;;;AAAA;;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACNA;AACA;;;;ACDA;AACA;AACA;AACA;AACA;AACA","sources":[".././src/compress.js",".././src/constants.js",".././src/event.js",".././src/github.js",".././src/main.js",".././src/octokit.js",".././src/template.js",".././src/wait.js","../../../.nvm/versions/node/v23.5.0/lib/node_modules/@vercel/ncc/dist/ncc/@@notfound.js","../external node-commonjs \"crypto\"","../external node-commonjs \"fs\"","../external node-commonjs \"path\"","../external node-commonjs \"util\"","../webpack/bootstrap","../webpack/runtime/define property getters","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/make namespace object","../webpack/runtime/compat",".././src/index.js"],"sourcesContent":["const util = require('util');\nconst core = require('@actions/core');\nconst { globSync } = require('glob');\nconst { requestDiffFiles } = require('./github');\nconst sharp = require('sharp');\nconst { extname } = require('path');\nconst { statSync, writeFileSync } = require('fs');\n\nconst {\n  IGNORE_PATHS,\n  JPEG_QUALITY,\n  JPEG_PROGRESSIVE,\n  PNG_QUALITY,\n  WEBP_QUALITY,\n  COMPRESS_ONLY,\n  EXTENSION_TO_SHARP_FORMAT_MAPPING\n} = require('./constants');\n\nconst config = {\n  jpeg: { quality: JPEG_QUALITY, progressive: JPEG_PROGRESSIVE },\n  png: { quality: PNG_QUALITY },\n  webp: { quality: WEBP_QUALITY },\n  ignorePaths: IGNORE_PATHS,\n  compressOnly: COMPRESS_ONLY\n};\n\nasync function compress() {\n  const diffFiles = await requestDiffFiles();\n  const files = globSync(diffFiles, {\n    ignore: IGNORE_PATHS,\n    nodir: true,\n    follow: false,\n    dot: true\n  });\n\n  let optimisedImages = [];\n  let unoptimisedImages = [];\n\n  for (const file of files) {\n    try {\n      core.info(`file ${file}`);\n      const beforeStat = statSync(file).size;\n      const extension = extname(file);\n      const sharpFormat = EXTENSION_TO_SHARP_FORMAT_MAPPING[extension];\n\n      const { data, info } = await sharp(file)\n        .toFormat(sharpFormat, config[sharpFormat])\n        .toBuffer({ resolveWithObject: true });\n\n      const name = file.split('/').slice(-2).join('/');\n      const afterStat = info.size;\n      const percentChange = (afterStat / beforeStat) * 100 - 100;\n\n      const compressionWasSignificant = percentChange < -1;\n\n      const processedImage = {\n        name,\n        content: data,\n        path: file,\n        beforeStat,\n        afterStat,\n        percentChange,\n        compressionWasSignificant\n      };\n\n      if (compressionWasSignificant) {\n        writeFileSync(file, data);\n\n        optimisedImages.push(processedImage);\n      } else {\n        unoptimisedImages.push(processedImage);\n      }\n    } catch (error) {\n      core.error(error);\n      core.error(`Error on processing ${file}`);\n    }\n  }\n\n  return {\n    optimisedImages,\n    unoptimisedImages\n  };\n}\n\nmodule.exports = compress;\n","const path = require('path')\nconst core = require('@actions/core')\n\nconst REPO_DIRECTORY = process.env['GITHUB_WORKSPACE']\nconst GITHUB_EVENT_PATH = process.env['GITHUB_EVENT_PATH']\nconst GITHUB_TOKEN =\n  process.env['INPUT_GITHUBTOKEN'] || process.env['GITHUB_TOKEN']\n\nconst JPEG_QUALITY = parseInt(core.getInput('jpegQuality') || 80)\nconst PNG_QUALITY = parseInt(core.getInput('pngQuality') || 80)\nconst WEBP_QUALITY = parseInt(core.getInput('webpQuality') || 80)\n\nconst COMPRESS_ONLY = (core.getInput('compressOnly') || 'true') === 'true'\nconst JPEG_PROGRESSIVE = (core.getInput('jpegProgressive') || 'true') === 'true'\n\nconst IGNORE_PATHS = process.env['INPUT_IGNOREPATHS']\n  ? process.env['INPUT_IGNOREPATHS'].split(',')\n  : []\n\nconst EXTENSION_TO_SHARP_FORMAT_MAPPING = {\n  '.png': 'png',\n  '.jpg': 'jpeg',\n  '.jpeg': 'jpeg',\n  '.webp': 'webp'\n}\n\nconst COMMITER = {\n  name: process.env['INPUT_COMMITERNAME'],\n  email: process.env['INPUT_COMMITEREMAIL']\n}\n\nconst CONFIG_PATH = path.join(\n  REPO_DIRECTORY,\n  '.github/ZeckWork/compress-images.yml'\n)\n\nexport {\n  COMMITER,\n  CONFIG_PATH,\n  IGNORE_PATHS,\n  GITHUB_TOKEN,\n  REPO_DIRECTORY,\n  GITHUB_EVENT_PATH,\n  EXTENSION_TO_SHARP_FORMAT_MAPPING,\n  JPEG_QUALITY,\n  PNG_QUALITY,\n  WEBP_QUALITY,\n  COMPRESS_ONLY,\n  JPEG_PROGRESSIVE\n}\n","const { readFileSync } = require('fs');\nconst { GITHUB_EVENT_PATH } = require('./constants');\n\nconst buffer = readFileSync(GITHUB_EVENT_PATH);\n\nmodule.exports = JSON.parse(buffer.toString());\n","const { readFileSync } = require('fs');\nconst event = require('./event');\nconst { rest } = require('./octokit');\nconst { COMMITER, REPO_DIRECTORY } = require('./constants');\n\nconst { number, repository, pull_request } = event;\n\nasync function requestDiffFiles() {\n  const pull_number = number;\n  const repo = repository.name;\n  const owner = repository.owner.login;\n\n  const response = await rest.pulls.listFiles({\n    owner,\n    repo,\n    pull_number,\n    mediaType: {\n      format: 'text'\n    }\n  });\n\n  return response.data\n    .filter(file => file.status != 'removed')\n    .map(file => `${REPO_DIRECTORY}/**/${file.filename.split('/').slice(-1)}`);\n}\n\nasync function requestLastCommitInTree() {\n  const repo = repository.name;\n  const owner = repository.owner.login;\n  const commit_sha = pull_request.head.sha;\n\n  const response = await rest.git.getCommit({\n    owner,\n    repo,\n    commit_sha\n  });\n\n  return response.data.tree.sha;\n}\n\nasync function requestCreateBlob(image) {\n  const { name, path } = image;\n  const encoding = 'base64';\n  const content = readFileSync(path, { encoding });\n\n  const repo = repository.name;\n  const owner = repository.owner.login;\n\n  const response = await rest.git.createBlob({\n    repo,\n    owner,\n    encoding,\n    content\n  });\n\n  return {\n    path: name,\n    type: 'blob',\n    mode: '100644',\n    sha: response.data.sha\n  };\n}\n\nasync function requestTree(base_tree, tree) {\n  const repo = repository.name;\n  const owner = repository.owner.login;\n\n  const response = await rest.git.createTree({\n    owner,\n    repo,\n    base_tree,\n    tree\n  });\n\n  return response.data.sha;\n}\n\nasync function requestCommitChanges(message, tree) {\n  const repo = repository.name;\n  const owner = repository.owner.login;\n  const ref = pull_request.head.sha;\n\n  const response = await rest.git.createCommit({\n    repo,\n    owner,\n    message,\n    tree,\n    parents: [ref],\n    committer: COMMITER\n  });\n\n  return response.data;\n}\n\nasync function requestUpdateRef(sha) {\n  const repo = repository.name;\n  const owner = repository.owner.login;\n  const ref = pull_request.head.ref;\n\n  await rest.git.updateRef({\n    owner,\n    repo,\n    ref,\n    sha\n  });\n}\n\nasync function requestComment(body) {\n  const repo = repository.name;\n  const owner = repository.owner.login;\n\n  rest.issues.createComment({\n    owner,\n    repo,\n    issue_number: number,\n    body\n  });\n}\n\nmodule.exports = {\n  requestDiffFiles,\n  requestLastCommitInTree,\n  requestCreateBlob,\n  requestTree,\n  requestCommitChanges,\n  requestUpdateRef,\n  requestComment\n};\n","const core = require('@actions/core')\nconst { wait } = require('./wait')\nconst compress = require('./compress').default\nconst {\n  requestCommitChanges,\n  requestLastCommitInTree,\n  requestTree,\n  requestCreateBlob,\n  requestUpdateRef,\n  requestComment\n} = require('./github').default\nconst generateMarkdownReport = require('./template')\n\n/**\n * The main function for the action.\n * @returns {Promise<void>} Resolves when the action is complete.\n */\nasync function run() {\n  try {\n    const images = await compress()\n    const { optimisedImages } = images\n\n    core.debug('optimisedImages: ', `${JSON.stringify(optimisedImages)}`)\n\n    const baseTree = await requestLastCommitInTree()\n    let blobs = []\n\n    for (var i = 0; i < optimisedImages.length; i++) {\n      const image = await requestCreateBlob(optimisedImages[i])\n      blobs.push(image)\n      core.info(image)\n    }\n\n    if (optimisedImages.length == 0) {\n      core.info('No optmized images')\n      return\n    }\n\n    const tree = await requestTree(baseTree, blobs)\n\n    const commit = await requestCommitChanges(\n      'refactor: imagens otimizadas.',\n      tree\n    )\n\n    core.debug(JSON.stringify(commit))\n\n    await requestUpdateRef(commit.sha)\n\n    await requestComment(await generateMarkdownReport(images))\n  } catch (error) {\n    // Fail the workflow run if an error occurs\n    core.setFailed(error.message)\n  }\n}\n\nmodule.exports = {\n  run\n}\n","const core = require('@actions/core')\nconst { getOctokit } = require('@actions/github')\n\nconst GITHUB_TOKEN = core.getInput('github_token')\n\nmodule.exports = getOctokit(GITHUB_TOKEN)\n",null,"/**\n * Wait for a number of milliseconds.\n *\n * @param {number} milliseconds The number of milliseconds to wait.\n * @returns {Promise<string>} Resolves with 'done!' after the wait is over.\n */\nasync function wait(milliseconds) {\n  return new Promise(resolve => {\n    if (isNaN(milliseconds)) {\n      throw new Error('milliseconds not a number')\n    }\n\n    setTimeout(() => resolve('done!'), milliseconds)\n  })\n}\n\nmodule.exports = { wait }\n",null,"module.exports = require(\"crypto\");","module.exports = require(\"fs\");","module.exports = require(\"path\");","module.exports = require(\"util\");","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = __dirname + \"/\";","/**\n * The entrypoint for the action.\n */\nconst { run } = require('./main')\n\nrun()\n"],"names":[],"sourceRoot":""}